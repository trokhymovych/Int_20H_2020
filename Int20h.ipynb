{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.13.1 in /Users/trokhymovych/.local/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (3.10.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.33.4)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.16.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (0.9.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.27.2)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorflow==1.13.1) (1.13.1)\n",
      "Requirement already satisfied: setuptools in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.0.1)\n",
      "Requirement already satisfied: h5py in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.9.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (3.0.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/trokhymovych/.local/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/trokhymovych/anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.15.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorflow-gpu -y --user\n",
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.kaggle’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir .kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "token = {\"username\": \"trokhymovych\", \"key\": \"071d0c0ef7f58991684890d02542875e\"}\n",
    "with open('.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp .kaggle/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- path is now set to: {/content}\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle config set -n path -v{/content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading evohackaton.zip to {/content}/competitions/evohackaton\n",
      "100%|█████████████████████████████████████▉| 2.67G/2.67G [02:07<00:00, 26.6MB/s]\n",
      "100%|██████████████████████████████████████| 2.67G/2.67G [02:07<00:00, 22.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c evohackaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip {/content}/competitions/evohackaton/evohackaton.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import glob\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model \n",
    "from tensorflow.keras.models import Sequential \n",
    "from keras import layers\n",
    "from keras.layers import Conv2D,MaxPooling2D, BatchNormalization, Dropout, GlobalAveragePooling2D, Dense, Flatten\n",
    "from keras import optimizers\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general direction\n",
    "dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of dictionary: 16857\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from the  data file: {img.jpg : lable}\n",
    "\n",
    "# Go to label directiory and tranfer labels to pd\n",
    "labels = pd.read_csv(dir + 'train.csv').set_index('name')\n",
    "\n",
    "# Convert pd to dic -> {Image.jpg : label}\n",
    "labels = labels.to_dict()\n",
    "labels = labels[list(labels.keys())[0]]\n",
    "\n",
    "print(f'lenght of dictionary: {len(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        images\n",
       "labels        \n",
       "0          251\n",
       "1          155\n",
       "10          89\n",
       "11         187\n",
       "12         131"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a PD dataframe with columns Images and Labels\n",
    "# This DF is needed for the flow_from_dataframe method of the ImageDataGenerator class\n",
    "df = pd.DataFrame(list(labels.items()))\n",
    "df.columns = ['images', 'labels']\n",
    "df = df.astype({'labels': str})\n",
    "\n",
    "# Display the occurance of each class\n",
    "df.groupby('labels').count().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: (15171, 2)\n",
      "validation_df: (1686, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = train_test_split(df, test_size=0.1)\n",
    "\n",
    "print(f'train_df: {train_df.shape}')\n",
    "print(f'validation_df: {validation_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999.jpg</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11636</th>\n",
       "      <td>11636.jpg</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>10728.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7829</th>\n",
       "      <td>7829.jpg</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          images labels\n",
       "14999  14999.jpg     39\n",
       "11636  11636.jpg     42\n",
       "10728  10728.jpg      0\n",
       "7829    7829.jpg     57\n",
       "179      179.jpg     14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing settings for training data\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=15,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    shear_range=0.01,\n",
    "    zoom_range=[0.9, 1.25],\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "# Preprocessing settings for test data\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15171 validated image filenames belonging to 100 classes.\n",
      "Found 1686 validated image filenames belonging to 100 classes.\n"
     ]
    }
   ],
   "source": [
    "# Apply data transfers and create generators for training and test data\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory='train/train',\n",
    "        x_col=\"images\",\n",
    "        y_col=\"labels\",\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=validation_df,\n",
    "        directory='train/train',\n",
    "        x_col=\"images\",\n",
    "        y_col=\"labels\",\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "38092800/87910968 [===========>..................] - ETA: 48s"
     ]
    }
   ],
   "source": [
    "# Cell below is used to initiate a cnn network\n",
    "# Specify the shape of inputs\n",
    "input_shape = (256,256,3)\n",
    "batch_size = 32\n",
    "n_classes = 100\n",
    "\n",
    "# Set up model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=keras.layers.Input(shape=input_shape))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    "        \n",
    "x = base_model.output\n",
    "x = keras.layers.AveragePooling2D(pool_size=(6, 6))(x)\n",
    "x = keras.layers.Dropout(.4)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "predictions = keras.layers.Dense(n_classes, init='glorot_uniform', W_regularizer=l2(.0005), activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "# Display model\n",
    "model.summary()\n",
    "\n",
    "# Show if GPU is avialable\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initaite mode, specify the optimizer, lossfunction and metrics\n",
    "opt = keras.optimizers.SGD(lr=.01, momentum=.9)\n",
    "\n",
    "model.compile(optimizer = opt,\n",
    "              loss ='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Save weights if model improved\n",
    "filepath = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Early stopping in case val_loss < min_delta for a specific number of runs \n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.03, patience=5, verbose=1, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "# Set callbacks \n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same model as whole\n",
    "model.save(\"Inception_transfer_10epocs.h5\")\n",
    "\n",
    "# Fit data & train model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = train_generator.samples // batch_size,\n",
    "        callbacks = callbacks_list,\n",
    "        epochs = 1,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same model as whole\n",
    "model.save(\"Inception_transfer_10_epocs.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
